"""
LLM Client for Strategy Development and News Analysis
Connects to local Ollama instance for trading strategy assistance
"""
import requests
import json
from typing import Optional, Dict, Any, Lis
from datetime import datetime


class LLMClient:
    """Client for interacting with local LLM (Ollama)"""

    def __init__(self, base_url: str = "http://localhost:11434", model: str = "mistral"):
        self.base_url = base_url
        self.model = model
        self.timeout = 120  # 2 dakika timeou

    def ask(self, prompt: str, system_prompt: Optional[str] = None, temperature: float = 0.7) -> str:
        """
        LLM'e soru sor ve cevap al

        Args:
            prompt: KullanÄ±cÄ± sorusu
            system_prompt: Sistem rolÃ¼ (opsiyonel)
            temperature: YaratÄ±cÄ±lÄ±k seviyesi (0.0-1.0)

        Returns:
            LLM'in cevabÄ±
        """
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": temperature
            }
        }

        if system_prompt:
            payload["system"] = system_promp

        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=self.timeou
            )
            response.raise_for_status()
            result = response.json()
            return result.get("response", "").strip()

        except requests.exceptions.RequestException as e:
            return f"âŒ LLM baÄŸlantÄ± hatasÄ±: {e}"

    def analyze_news(self, news_items: List[Dict[str, Any]], symbol: str) -> Dict[str, Any]:
        """
        Haberleri analiz et ve sentiment + impact dÃ¶ndÃ¼r

        Args:
            news_items: Haber listesi (title, summary vb.)
            symbol: Sembol (BTC/USDT, NVDA, vb.)

        Returns:
            {
                "sentiment": "bullish" | "bearish" | "neutral",
                "impact": "low" | "medium" | "high" | "critical",
                "bias_score": -1.0 to 1.0,
                "confidence": 0.0 to 1.0,
                "summary": "Ã–zet aÃ§Ä±klama",
                "catalysts": ["katalizÃ¶r 1", "katalizÃ¶r 2", ...]
            }
        """
        # Haberleri metne dÃ¶nÃ¼ÅŸtÃ¼r
        news_text = "\n".join([
            f"- {item.get('title', '')} ({item.get('published', 'N/A')})"
            for item in news_items[-10:]  # Son 10 haber
        ])

        system_prompt = """Sen bir finansal analist ve trading uzmanÄ±sÄ±n.
Haberleri analiz edip bir varlÄ±ÄŸÄ±n fiyatÄ±na muhtemel etkisini deÄŸerlendiriyorsun.
CevabÄ±nÄ± JSON formatÄ±nda ver."""

        prompt = f"""
AÅŸaÄŸÄ±daki haberler {symbol} sembolÃ¼ ile ilgili:

{news_text}

LÃ¼tfen bu haberleri analiz et ve ÅŸu JSON formatÄ±nda cevap ver:

{{
  "sentiment": "bullish veya bearish veya neutral",
  "impact": "low veya medium veya high veya critical",
  "bias_score": -1.0 ile 1.0 arasÄ± sayÄ± (negatif=bearish, pozitif=bullish),
  "confidence": 0.0 ile 1.0 arasÄ± (analiz gÃ¼venirliÄŸi),
  "summary": "KÄ±sa Ã¶zet (max 2 cÃ¼mle)",
  "catalysts": ["ana katalizÃ¶r 1", "ana katalizÃ¶r 2"]
}}

SADECE JSON dÃ¶ndÃ¼r, baÅŸka aÃ§Ä±klama ekleme.
"""

        response = self.ask(prompt, system_prompt=system_prompt, temperature=0.3)

        # JSON parse e
        try:
            # JSON'u Ã§Ä±kar (eÄŸer markdown code block iÃ§indeyse)
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                response = response.split("```")[1].split("```")[0].strip()

            result = json.loads(response)
            return resul
        except json.JSONDecodeError:
            # Parse edilemezse default deÄŸerler
            return {
                "sentiment": "neutral",
                "impact": "low",
                "bias_score": 0.0,
                "confidence": 0.3,
                "summary": "LLM analizi parse edilemedi",
                "catalysts": []
            }

    def suggest_strategy(self,
                        symbol: str,
                        historical_performance: Dict[str, Any],
                        market_conditions: Dict[str, Any]) -> str:
        """
        Mevcut performans ve piyasa koÅŸullarÄ±na gÃ¶re strateji Ã¶nerisi

        Args:
            symbol: Sembol
            historical_performance: Backtest sonuÃ§larÄ±
            market_conditions: Piyasa durumu (volatilite, trend, vb.)

        Returns:
            Strateji Ã¶nerisi metni
        """
        system_prompt = """Sen bir algoritmik trading stratejisti ve quantitative analistisin.
Backtest sonuÃ§larÄ±nÄ± ve piyasa koÅŸullarÄ±nÄ± analiz edip strateji iyileÅŸtirmeleri Ã¶neriyorsun."""

        prompt = f"""
Sembol: {symbol}

Mevcut Performans:
- Sharpe Ratio: {historical_performance.get('sharpe_ratio', 'N/A')}
- Win Rate: {historical_performance.get('win_rate', 'N/A')}%
- Max Drawdown: {historical_performance.get('max_drawdown_pct', 'N/A')}%
- Total Return: {historical_performance.get('total_pnl_pct', 'N/A')}%
- Total Trades: {historical_performance.get('total_trades', 'N/A')}

Piyasa KoÅŸullarÄ±:
- Volatilite: {market_conditions.get('volatility', 'N/A')}
- Trend: {market_conditions.get('trend', 'N/A')}
- RSI: {market_conditions.get('rsi', 'N/A')}

Bu performansÄ± iyileÅŸtirmek iÃ§in:
1. Hangi parametreleri ayarlamalÄ±yÄ±m?
2. Hangi ek gÃ¶stergeleri eklemeliyim?
3. Risk yÃ¶netimi nasÄ±l optimize edilir?
4. Bu piyasa koÅŸullarÄ±nda hangi strateji tipi daha uygun? (trend-following, mean-reversion, vb.)

LÃ¼tfen somut, uygulanabilir Ã¶neriler ver.
"""

        return self.ask(prompt, system_prompt=system_prompt, temperature=0.7)

    def optimize_parameters(self,
                           symbol: str,
                           current_params: Dict[str, Any],
                           performance_history: List[Dict[str, Any]]) -> str:
        """
        Parametre optimizasyonu Ã¶nerisi

        Args:
            symbol: Sembol
            current_params: Mevcut parametreler
            performance_history: FarklÄ± parametre kombinasyonlarÄ±nÄ±n performansÄ±

        Returns:
            Optimizasyon Ã¶nerisi
        """
        system_prompt = """Sen bir parametre optimizasyon uzmanÄ±sÄ±n.
Grid search veya Bayesian optimization sonuÃ§larÄ±nÄ± yorumlayÄ±p en iyi yaklaÅŸÄ±mÄ± Ã¶neriyorsun."""

        # En iyi 5 kombinasyonu al
        top_5 = sorted(performance_history, key=lambda x: x.get('sharpe_ratio', 0), reverse=True)[:5]

        prompt = f"""
Sembol: {symbol}

Mevcut Parametreler:
{json.dumps(current_params, indent=2)}

En Ä°yi 5 Kombinasyon:
{json.dumps(top_5, indent=2)}

Bu sonuÃ§lara bakarak:
1. Hangi parametreler performansÄ± en Ã§ok etkiliyor?
2. Parametreler arasÄ±nda nasÄ±l bir iliÅŸki var?
3. Overfitting riski var mÄ±?
4. Ã–nerilen yeni parametre aralÄ±klarÄ± neler?

Somut sayÄ±sal Ã¶neriler ver.
"""

        return self.ask(prompt, system_prompt=system_prompt, temperature=0.5)

    def explain_trade(self,
                     trade_data: Dict[str, Any],
                     market_context: Dict[str, Any]) -> str:
        """
        Bir iÅŸlemin neden aÃ§Ä±ldÄ±ÄŸÄ±nÄ±/kapatÄ±ldÄ±ÄŸÄ±nÄ± aÃ§Ä±kla

        Args:
            trade_data: Ä°ÅŸlem detaylarÄ±
            market_context: Piyasa durumu

        Returns:
            AÃ§Ä±klama metni
        """
        system_prompt = """Sen bir trading educator'Ä±sÄ±n.
Ä°ÅŸlemleri aÃ§Ä±k ve anlaÅŸÄ±lÄ±r ÅŸekilde aÃ§Ä±klÄ±yorsun."""

        prompt = f"""
Ä°ÅŸlem DetaylarÄ±:
- Side: {trade_data.get('side', 'N/A')}
- Entry: ${trade_data.get('entry_price', 'N/A')}
- Exit: ${trade_data.get('exit_price', 'N/A')}
- P&L: {trade_data.get('pnl_pct', 'N/A')}%
- Exit Reason: {trade_data.get('exit_reason', 'N/A')}

Piyasa Durumu:
- EMA Fast: {market_context.get('ema_fast', 'N/A')}
- EMA Slow: {market_context.get('ema_slow', 'N/A')}
- RSI: {market_context.get('rsi', 'N/A')}
- Fiyat: ${market_context.get('price', 'N/A')}

Bu iÅŸlemi neden aÃ§tÄ±k ve neden bu ÅŸekilde kapandÄ±?
Teknik analizle aÃ§Ä±kla (2-3 cÃ¼mle).
"""

        return self.ask(prompt, system_prompt=system_prompt, temperature=0.5)

    def health_check(self) -> bool:
        """LLM servisinin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol et"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False


# Global instance
_llm_client = None

def get_llm_client(model: str = "mistral") -> LLMClient:
    """Singleton LLM client al"""
    global _llm_clien
    if _llm_client is None:
        _llm_client = LLMClient(model=model)
    return _llm_clien


if __name__ == "__main__":
    # Tes
    client = LLMClient()

    print("ğŸ” LLM Health Check...")
    if client.health_check():
        print("âœ… LLM servisi Ã§alÄ±ÅŸÄ±yor!")
    else:
        print("âŒ LLM servisi yanÄ±t vermiyor. 'ollama serve' Ã§alÄ±ÅŸtÄ±rÄ±n.")
        exit(1)

    print("\nğŸ¤– Test Sorusu...")
    response = client.ask("Bitcoin iÃ§in EMA crossover stratejisi ne zaman long pozisyon aÃ§ar? KÄ±sa aÃ§Ä±kla.")
    print(f"Cevap: {response}")

    print("\nğŸ“° Haber Analizi Test...")
    test_news = [
        {"title": "Fed faiz artÄ±rÄ±mÄ±na devam edeceÄŸini aÃ§Ä±kladÄ±", "published": "2025-11-01"},
        {"title": "Bitcoin ETF onaylarÄ± yaklaÅŸÄ±yor", "published": "2025-11-01"},
    ]
    analysis = client.analyze_news(test_news, "BTC/USDT")
    print(f"Analiz: {json.dumps(analysis, indent=2, ensure_ascii=False)}")

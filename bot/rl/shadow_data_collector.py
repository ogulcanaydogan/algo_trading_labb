"""
Shadow Data Collector for Paper Trading.

Phase 2B Requirement:
Collects comprehensive shadow data during paper trading for counterfactual analysis:
- RL recommendations at each decision point
- Gate decisions and rejection reasons
- Realized outcomes (PnL, MAE/MFE)
- Execution costs (slippage, fees, spread)
- Regime and news sentiment snapshots

CRITICAL: Collection only. No execution authority.
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from bot.rl.shadow_advisor import (
    RLShadowAdvisor,
    ShadowModeConfig,
    RLAdvisoryMode,
    RLRecommendation,
    get_shadow_advisor,
)
from bot.rl.multi_agent_system import MarketState

logger = logging.getLogger(__name__)


# Data mode constants
DATA_MODE_TEST = "TEST"
DATA_MODE_PAPER_LIVE = "PAPER_LIVE"


@dataclass
class DecisionSnapshot:
    """Complete snapshot of a trading decision point."""
    timestamp: datetime = field(default_factory=datetime.now)
    decision_id: str = ""

    # Data mode: TEST (generated by scripts) or PAPER_LIVE (from live paper trading)
    data_mode: str = DATA_MODE_PAPER_LIVE

    # Symbol and market context
    symbol: str = ""
    price: float = 0.0
    volatility: float = 0.0
    spread_bps: float = 0.0
    daily_volume: float = 0.0

    # Regime context
    regime: str = "unknown"
    regime_confidence: float = 0.0

    # News/sentiment context
    news_sentiment: float = 0.0
    fear_greed_index: float = 50.0

    # RL recommendation
    rl_enabled: bool = False
    rl_action: str = "hold"
    rl_confidence: float = 0.0
    rl_primary_agent: str = ""
    rl_strategy_preferences: Dict[str, float] = field(default_factory=dict)
    rl_directional_bias: str = "neutral"

    # Gate decision
    gate_approved: bool = True
    gate_score: float = 0.0
    gate_rejection_reason: str = ""
    gate_trace: Dict[str, Any] = field(default_factory=dict)

    # Capital preservation state
    preservation_level: str = "normal"
    preservation_restrictions: Dict[str, float] = field(default_factory=dict)

    # Actual decision made
    actual_action: str = "hold"
    actual_confidence: float = 0.0
    strategy_used: str = ""

    # Execution details (filled after trade)
    executed: bool = False
    entry_price: float = 0.0
    exit_price: float = 0.0
    position_size: float = 0.0
    leverage: float = 1.0

    # Costs (filled after trade)
    slippage_cost: float = 0.0
    fee_cost: float = 0.0
    spread_cost: float = 0.0
    total_cost: float = 0.0

    # Outcome (filled after trade closes)
    pnl: float = 0.0
    pnl_pct: float = 0.0
    mae: float = 0.0  # Maximum adverse excursion
    mfe: float = 0.0  # Maximum favorable excursion
    holding_time_minutes: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        """Convert to JSON-serializable dict."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "decision_id": self.decision_id,
            "data_mode": self.data_mode,
            "symbol": self.symbol,
            "market_context": {
                "price": self.price,
                "volatility": self.volatility,
                "spread_bps": self.spread_bps,
                "daily_volume": self.daily_volume,
            },
            "regime_context": {
                "regime": self.regime,
                "regime_confidence": self.regime_confidence,
            },
            "sentiment_context": {
                "news_sentiment": self.news_sentiment,
                "fear_greed_index": self.fear_greed_index,
            },
            "rl_recommendation": {
                "enabled": self.rl_enabled,
                "action": self.rl_action,
                "confidence": self.rl_confidence,
                "primary_agent": self.rl_primary_agent,
                "strategy_preferences": self.rl_strategy_preferences,
                "directional_bias": self.rl_directional_bias,
            },
            "gate_decision": {
                "approved": self.gate_approved,
                "score": self.gate_score,
                "rejection_reason": self.gate_rejection_reason,
            },
            "gate_trace": self.gate_trace,
            "preservation_state": {
                "level": self.preservation_level,
                "restrictions": self.preservation_restrictions,
            },
            "actual_decision": {
                "action": self.actual_action,
                "confidence": self.actual_confidence,
                "strategy_used": self.strategy_used,
            },
            "execution": {
                "executed": self.executed,
                "entry_price": self.entry_price,
                "exit_price": self.exit_price,
                "position_size": self.position_size,
                "leverage": self.leverage,
            },
            "costs": {
                "slippage": self.slippage_cost,
                "fees": self.fee_cost,
                "spread": self.spread_cost,
                "total": self.total_cost,
            },
            "outcome": {
                "pnl": self.pnl,
                "pnl_pct": self.pnl_pct,
                "mae": self.mae,
                "mfe": self.mfe,
                "holding_time_minutes": self.holding_time_minutes,
            },
        }


@dataclass
class ShadowCollectorConfig:
    """Configuration for shadow data collection."""
    enabled: bool = True
    log_path: Path = field(default_factory=lambda: Path("data/rl/shadow_decisions.jsonl"))
    enable_rl_shadow: bool = True  # Enable RL shadow mode
    min_confidence_to_log: float = 0.0  # Log all decisions
    batch_size: int = 100  # Batch writes


class ShadowDataCollector:
    """
    Collects comprehensive decision data for counterfactual analysis.

    Integrates with paper trading to capture:
    - Every decision point
    - RL recommendations
    - Gate decisions
    - Outcomes

    CRITICAL: Collection only. No execution authority.
    """

    def __init__(self, config: Optional[ShadowCollectorConfig] = None):
        self.config = config or ShadowCollectorConfig()
        self._decisions: List[DecisionSnapshot] = []
        self._pending_decisions: Dict[str, DecisionSnapshot] = {}  # By decision_id
        self._decision_counter = 0

        # Session counters for heartbeat tracking (ALL decision points, not just executed)
        self._total_decisions_session: int = 0
        self._paper_live_decisions_session: int = 0
        self._last_decision_ts: Optional[str] = None

        # Initialize RL shadow advisor if enabled
        self._shadow_advisor: Optional[RLShadowAdvisor] = None
        if self.config.enable_rl_shadow:
            shadow_config = ShadowModeConfig(
                enabled=True,
                mode=RLAdvisoryMode.SHADOW,
                log_all_recommendations=True,
            )
            self._shadow_advisor = get_shadow_advisor(shadow_config)

        # Ensure log directory exists
        self.config.log_path.parent.mkdir(parents=True, exist_ok=True)

        logger.info(
            f"ShadowDataCollector initialized: "
            f"rl_shadow={self.config.enable_rl_shadow}, "
            f"log_path={self.config.log_path}"
        )

    def _generate_decision_id(self) -> str:
        """Generate unique decision ID."""
        self._decision_counter += 1
        return f"DEC_{datetime.now().strftime('%Y%m%d%H%M%S')}_{self._decision_counter:04d}"

    def record_decision_point(
        self,
        symbol: str,
        market_state: MarketState,
        gate_approved: bool,
        gate_score: float = 0.0,
        gate_rejection_reason: str = "",
        gate_trace: Optional[Dict[str, Any]] = None,
        preservation_level: str = "normal",
        preservation_restrictions: Optional[Dict[str, float]] = None,
        actual_action: str = "hold",
        actual_confidence: float = 0.0,
        strategy_used: str = "",
    ) -> str:
        """
        Record a trading decision point with full context.

        Args:
            symbol: Trading symbol
            market_state: Current market state
            gate_approved: Whether TradeGate approved
            gate_score: TradeGate score
            gate_rejection_reason: Reason for rejection if any
            preservation_level: Current capital preservation level
            preservation_restrictions: Current restrictions
            actual_action: Action actually taken
            actual_confidence: Confidence of actual action
            strategy_used: Strategy that made the decision

        Returns:
            decision_id for tracking outcome
        """
        if not self.config.enabled:
            return ""

        decision_id = self._generate_decision_id()

        # Get RL recommendation
        rl_rec = None
        if self._shadow_advisor and self._shadow_advisor.is_enabled():
            rl_rec = self._shadow_advisor.get_recommendation(
                symbol=symbol,
                market_state=market_state,
                preservation_level=preservation_level,
                gate_approved=gate_approved,
            )

        # Create snapshot with PAPER_LIVE data mode
        now = datetime.now()
        snapshot = DecisionSnapshot(
            timestamp=now,
            decision_id=decision_id,
            data_mode=DATA_MODE_PAPER_LIVE,  # Always PAPER_LIVE from live paper trading
            symbol=symbol,
            price=market_state.price,
            volatility=market_state.volatility,
            spread_bps=5.0,  # Default estimate
            daily_volume=1_000_000_000,  # Default estimate

            regime=market_state.regime,
            regime_confidence=0.7,  # Default

            news_sentiment=market_state.news_sentiment,
            fear_greed_index=market_state.fear_greed,

            rl_enabled=self._shadow_advisor.is_enabled() if self._shadow_advisor else False,
            rl_action=rl_rec.suggested_action if rl_rec else "hold",
            rl_confidence=rl_rec.action_confidence if rl_rec else 0.0,
            rl_primary_agent=rl_rec.primary_agent if rl_rec else "",
            rl_strategy_preferences=rl_rec.strategy_preferences if rl_rec else {},
            rl_directional_bias=rl_rec.directional_bias if rl_rec else "neutral",

            gate_approved=gate_approved,
            gate_score=gate_score,
            gate_rejection_reason=gate_rejection_reason,
            gate_trace=gate_trace or {},

            preservation_level=preservation_level,
            preservation_restrictions=preservation_restrictions or {},

            actual_action=actual_action,
            actual_confidence=actual_confidence,
            strategy_used=strategy_used,

            # Initially not executed - will be updated if trade proceeds
            executed=False,
        )

        self._pending_decisions[decision_id] = snapshot

        # Update session counters for heartbeat tracking
        self._total_decisions_session += 1
        self._paper_live_decisions_session += 1
        self._last_decision_ts = now.isoformat()

        # Write immediately to log (all decision points, not just executed)
        # This ensures HOLD, blocked, and rejected trades are captured
        self._write_decision(snapshot)

        logger.debug(
            f"Decision point recorded: {decision_id}, "
            f"RL={snapshot.rl_action}@{snapshot.rl_confidence:.2f}, "
            f"actual={actual_action}, data_mode=PAPER_LIVE"
        )

        return decision_id

    def record_execution(
        self,
        decision_id: str,
        entry_price: float,
        position_size: float,
        leverage: float = 1.0,
        slippage_cost: float = 0.0,
        fee_cost: float = 0.0,
        spread_cost: float = 0.0,
    ):
        """
        Record execution details for a decision.

        Args:
            decision_id: ID from record_decision_point
            entry_price: Actual entry price
            position_size: Position size
            leverage: Leverage used
            slippage_cost: Slippage cost in USD
            fee_cost: Fee cost in USD
            spread_cost: Spread cost in USD
        """
        if decision_id not in self._pending_decisions:
            logger.warning(f"Unknown decision_id for execution: {decision_id}")
            return

        snapshot = self._pending_decisions[decision_id]
        snapshot.executed = True
        snapshot.entry_price = entry_price
        snapshot.position_size = position_size
        snapshot.leverage = leverage
        snapshot.slippage_cost = slippage_cost
        snapshot.fee_cost = fee_cost
        snapshot.spread_cost = spread_cost
        snapshot.total_cost = slippage_cost + fee_cost + spread_cost

    def record_outcome(
        self,
        decision_id: str,
        exit_price: float,
        pnl: float,
        pnl_pct: float,
        mae: float = 0.0,
        mfe: float = 0.0,
        holding_time_minutes: float = 0.0,
    ):
        """
        Record trade outcome and finalize the decision record.

        Args:
            decision_id: ID from record_decision_point
            exit_price: Exit price
            pnl: Realized P&L in USD
            pnl_pct: Realized P&L as percentage
            mae: Maximum adverse excursion
            mfe: Maximum favorable excursion
            holding_time_minutes: How long position was held
        """
        if decision_id not in self._pending_decisions:
            logger.warning(f"Unknown decision_id for outcome: {decision_id}")
            return

        snapshot = self._pending_decisions.pop(decision_id)
        snapshot.exit_price = exit_price
        snapshot.pnl = pnl
        snapshot.pnl_pct = pnl_pct
        snapshot.mae = mae
        snapshot.mfe = mfe
        snapshot.holding_time_minutes = holding_time_minutes

        self._decisions.append(snapshot)

        # Record to RL shadow advisor for counterfactual tracking
        if self._shadow_advisor:
            self._shadow_advisor.record_outcome(
                symbol=snapshot.symbol,
                actual_action=snapshot.actual_action,
                pnl=pnl,
            )

        # Write to log
        self._write_decision(snapshot)

        # Batch write if needed
        if len(self._decisions) >= self.config.batch_size:
            self._flush_batch()

        logger.debug(
            f"Outcome recorded: {decision_id}, "
            f"pnl=${pnl:.2f}, mae={mae:.2f}, mfe={mfe:.2f}"
        )

    def _write_decision(self, snapshot: DecisionSnapshot):
        """Write single decision to log file."""
        try:
            with open(self.config.log_path, "a") as f:
                f.write(json.dumps(snapshot.to_dict()) + "\n")
        except Exception as e:
            logger.error(f"Failed to write decision: {e}")

    def _flush_batch(self):
        """Flush batch of decisions (if using batched writes)."""
        # Currently writing immediately, but could batch here
        pass

    def record_to_database(
        self,
        db,  # LearningDatabase
        snapshot: DecisionSnapshot,
    ) -> Optional[int]:
        """
        Record decision to LearningDatabase for counterfactual analysis.

        Args:
            db: LearningDatabase instance
            snapshot: DecisionSnapshot to record

        Returns:
            Recommendation ID if recorded, None otherwise
        """
        try:
            rec_id = db.record_rl_recommendation(
                symbol=snapshot.symbol,
                regime=snapshot.regime,
                preservation_level=snapshot.preservation_level,
                strategy_preferences=snapshot.rl_strategy_preferences,
                directional_bias=snapshot.rl_directional_bias,
                bias_confidence=snapshot.rl_confidence,
                suggested_action=snapshot.rl_action,
                action_confidence=snapshot.rl_confidence,
                primary_agent=snapshot.rl_primary_agent,
                agent_reasoning="",
                agent_votes={},
                was_applied=snapshot.executed,
                application_reason="shadow_data_collection",
            )

            # Update with outcome if available
            if snapshot.pnl != 0:
                db.update_rl_recommendation_outcome(
                    recommendation_id=rec_id,
                    actual_action=snapshot.actual_action,
                    actual_pnl=snapshot.pnl,
                )

            return rec_id

        except Exception as e:
            logger.error(f"Failed to record to database: {e}")
            return None

    def get_collection_stats(self) -> Dict[str, Any]:
        """Get statistics about collected data."""
        completed = self._decisions
        pending = list(self._pending_decisions.values())

        # Session counters reflect ALL decision points (including blocked/HOLD)
        # These are what the heartbeat should report
        base_stats = {
            "total_decisions": self._total_decisions_session,
            "paper_live_decisions": self._paper_live_decisions_session,
            "pending_decisions": len(pending),
            "completed_trades": len(completed),
            "last_decision_ts": self._last_decision_ts,
            "rl_enabled": self._shadow_advisor.is_enabled() if self._shadow_advisor else False,
        }

        if not completed:
            return base_stats

        # Calculate stats from completed trades
        total_pnl = sum(d.pnl for d in completed)
        total_cost = sum(d.total_cost for d in completed)
        rl_followed = sum(1 for d in completed if d.rl_action == d.actual_action)

        by_symbol = {}
        for d in completed:
            if d.symbol not in by_symbol:
                by_symbol[d.symbol] = {"count": 0, "pnl": 0.0}
            by_symbol[d.symbol]["count"] += 1
            by_symbol[d.symbol]["pnl"] += d.pnl

        base_stats.update({
            "rl_agreement_rate": rl_followed / len(completed) if completed else 0,
            "total_pnl": round(total_pnl, 2),
            "total_cost": round(total_cost, 2),
            "avg_pnl_per_decision": round(total_pnl / len(completed), 4) if completed else 0,
            "by_symbol": by_symbol,
            "collection_period": {
                "start": completed[0].timestamp.isoformat() if completed else None,
                "end": completed[-1].timestamp.isoformat() if completed else None,
            },
        })

        return base_stats

    def reset(self):
        """Reset collector state."""
        self._decisions = []
        self._pending_decisions = {}
        self._decision_counter = 0
        self._total_decisions_session = 0
        self._paper_live_decisions_session = 0
        self._last_decision_ts = None
        logger.info("ShadowDataCollector reset")


# =============================================================================
# Heartbeat for PAPER_LIVE verification
# =============================================================================

@dataclass
class PaperLiveHeartbeat:
    """Heartbeat data for paper-live trading verification."""
    timestamp: str
    pid: int
    mode: str = DATA_MODE_PAPER_LIVE
    shadow_collector_attached: bool = True
    symbols: List[str] = field(default_factory=list)
    last_decision_ts: Optional[str] = None
    total_decisions_session: int = 0
    paper_live_decisions_session: int = 0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "timestamp": self.timestamp,
            "pid": self.pid,
            "mode": self.mode,
            "shadow_collector_attached": self.shadow_collector_attached,
            "symbols": self.symbols,
            "last_decision_ts": self.last_decision_ts,
            "total_decisions_session": self.total_decisions_session,
            "paper_live_decisions_session": self.paper_live_decisions_session,
        }


# Default heartbeat path
HEARTBEAT_PATH = Path("data/rl/paper_live_heartbeat.json")


def write_paper_live_heartbeat(
    symbols: List[str],
    last_decision_ts: Optional[str] = None,
    total_decisions: int = 0,
    paper_live_decisions: int = 0,
    heartbeat_path: Path = HEARTBEAT_PATH,
) -> None:
    """
    Write paper-live heartbeat file.

    Called by paper trading engine to indicate shadow collector is attached
    and actively collecting decisions.

    Args:
        symbols: List of symbols being traded
        last_decision_ts: Timestamp of last decision (ISO format)
        total_decisions: Total decisions this session
        paper_live_decisions: PAPER_LIVE decisions this session
        heartbeat_path: Path to heartbeat file
    """
    import os

    heartbeat = PaperLiveHeartbeat(
        timestamp=datetime.now().isoformat(),
        pid=os.getpid(),
        mode=DATA_MODE_PAPER_LIVE,
        shadow_collector_attached=True,
        symbols=symbols,
        last_decision_ts=last_decision_ts,
        total_decisions_session=total_decisions,
        paper_live_decisions_session=paper_live_decisions,
    )

    heartbeat_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        with open(heartbeat_path, "w") as f:
            json.dump(heartbeat.to_dict(), f, indent=2)
        logger.info(
            f"Paper-live heartbeat written: pid={heartbeat.pid}, "
            f"symbols={symbols}, decisions={total_decisions}"
        )
    except Exception as e:
        logger.error(f"Failed to write heartbeat: {e}")


def read_paper_live_heartbeat(
    heartbeat_path: Path = HEARTBEAT_PATH,
) -> Optional[Dict[str, Any]]:
    """
    Read paper-live heartbeat file.

    Returns:
        Heartbeat data dict or None if not found/invalid
    """
    if not heartbeat_path.exists():
        return None

    try:
        with open(heartbeat_path) as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        logger.warning(f"Failed to read heartbeat: {e}")
        return None


def is_heartbeat_recent(
    heartbeat: Dict[str, Any],
    max_age_hours: float = 2.0,
) -> bool:
    """
    Check if heartbeat is recent (within max_age_hours).

    Args:
        heartbeat: Heartbeat data dict
        max_age_hours: Maximum age in hours to consider "recent"

    Returns:
        True if heartbeat is recent, False otherwise
    """
    try:
        timestamp_str = heartbeat.get("timestamp", "")
        if not timestamp_str:
            return False

        heartbeat_time = datetime.fromisoformat(timestamp_str)
        age = datetime.now() - heartbeat_time
        return age.total_seconds() < (max_age_hours * 3600)
    except (ValueError, TypeError):
        return False


def clear_paper_live_heartbeat(heartbeat_path: Path = HEARTBEAT_PATH) -> None:
    """Remove heartbeat file (e.g., on clean shutdown)."""
    try:
        if heartbeat_path.exists():
            heartbeat_path.unlink()
            logger.info("Paper-live heartbeat cleared")
    except Exception as e:
        logger.warning(f"Failed to clear heartbeat: {e}")


# =============================================================================
# Singleton instance
# =============================================================================

_collector: Optional[ShadowDataCollector] = None


def get_shadow_collector(
    config: Optional[ShadowCollectorConfig] = None
) -> ShadowDataCollector:
    """Get or create singleton ShadowDataCollector."""
    global _collector
    if _collector is None:
        _collector = ShadowDataCollector(config)
    return _collector


def reset_shadow_collector():
    """Reset singleton collector."""
    global _collector
    if _collector is not None:
        _collector.reset()
    _collector = None
